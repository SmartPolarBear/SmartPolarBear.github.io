[{"content":"It\u0026rsquo;s mid-2021, and this post, which is supposed to come out in Janurary, is finally complete. 2020 is a special year, both for the whole world and me. After consideration, I still believe that it deserve some record and hindsight for myself.\nSee Further  Entering the university, the courses, complicated and difficult, provide more higher perspective in understanding and analyzing than challenges. I had ever tried to apply transformations on image with GDI+, where all the adjustments made, like changes in brightness or saturation, are expressed in what\u0026rsquo;s called a transforming matrix. With few tools as a pupil, I, at that time, can only have a test on all the elements in that 5x5 matrix, or just copy codes and wish it could work, to provide certain features. But with the grab on linear algebra, now I can well understand how it works, and even more sophisticated designs like why it use a 5x5 matrix while only 4 channels of colors presented in the image. Through the tough journey of learning these abstract stuff, I am equipped with enough tools to see further, and know things better at the very beginning of every project.\nAbove all, I have made plans to read. It\u0026rsquo;s may be strange for a engineering student to read about labor movement and things, but I deem it important. The ancestors, being remembered or forgot, right before the dawn of a better society, risk their life to push the society forward, to defend their human rights. Their courage, and their devotion are worth knowing and remembering. Moreover, though I have basic knowledge and practical experience on them, I try to read famous materials and books about networking, data structures and algorithms. I am determined to synthesize and systematize my knowledge about them.\nDive Deeper  Yes, as a Computer Science student I have to code. But I do not want to be one who can only code. The whole year, most spent at home, provide me with ample time to read and learn more about what\u0026rsquo;s under the surface. It never a puzzle now for me that how a operation system kernel works, for I have tried to create one from scratch, and learned the supplicated design and the rigor logic \u0026ldquo;behind the curtain\u0026rdquo;, happening secretly when calling APIs , or syscalls. And, as the first of its kind for me, projects involving declarative-style UI and compilers have started. The cutting edge of the industry, and the basement of nearly everything, will soon be explored by me.\nGetting Involved  No one should be the slave of tests and scores. I firmly believe that everyone is supposed to develop their abilities in all ways, which is why I, despite tight schedule and academic pressure, get involved in various kind of things. I participate in acquisition and processing department of student union and have taken charge of some posts.\nMoreover, as a developer of open-source project, I take a more active part on GitHub, creating issues and making discussions. Helping others helped myself a lot. Not only because when helping others I learned about cope with various problems, but also because during the procedure I improve my ability to express.\nThere is one thing that delighted me so much. One is that I became an Arctic Code Vault Contributor. I mean, it\u0026rsquo;s surely no wonder for any contributers who have actively-developing project on GitHub, but as for me, for the first time, I find my hard work has been a part of the human history. It will never perish from the world in the storage in the arctic, and it\u0026rsquo;s a mark that I come to this world and live.\n","date":"2021-04-28T00:00:00+08:00","permalink":"https://xkzzzzzz.xyz/posts/looking-back-in-2020-provehito-in-altum/","title":"Looking Back to 2020: PROVEHITO IN ALTUM"},{"content":"Since years before C++ 20\u0026rsquo;s release, I have been keeping a close eye on it. Many new features fairly tickle my fancy, among which are \u0026lt;ranges\u0026gt; and \u0026lt;format\u0026gt; library components. While there\u0026rsquo;s no available implementation for \u0026lt;format\u0026gt; yet, MSVC 16.8 and GCC-10 provides a usable \u0026lt;ranges\u0026gt; which I played with and writes the post for.\nMy life highly involved closely with programming begins with a long period using C#. Among all the language features of C#, LINQ is the beloved one for me. Enabled by LINQ, I can express complicated queries clearly and elegantly, and the performance is ensured by delaying the evaluation to when the results is used. Years after my last C# project, the smooth feeling using LINQ still remain fresh in my memory. The ranges library, now, enable I to do it similarly, which is why I dash to have a try.\nTable of Contents  What is a Range Use Ranges Ranges and Constrained Algorithms Ranges and Range Adapters Lazy Evaluation Ranges and Coroutines Epilogue Further Reading  What is a Range?  As is mentioned in N4128 , A range is a reference to a sequence of elements:\n A range is an object that refers to a sequence of elements, conceptually similar to a pair of iterators.\n Bjarne Stroustrup, emphasized in his Thriving in a Crowded and Changing World: C++ 2006–2020, that :\n A range is a concept.\n A range is defined by concept as follows (from std::ranges::range on cppreference) :\ntemplate\u0026lt; class T \u0026gt; concept range = requires(T\u0026amp; t) { ranges::begin(t); // equality-preserving for forward iterators  ranges::end (t); }; The definition, given that you have known about STL containers, is quite easy to understand. Given begin() and end(), it constraints what can be iterated by an iterator and a sentinel that marks the end.\nIterators are constantly seen especially in STL to define a sequence, which provide a uniform interface to operate or traverse the elements and support some important language features like range-based for, while they do have some inconvenience. A simple example is to traverse part of a container whose elements satisfy a certain criterion with range-based for loop. Moreover, the increasing need for a way to avoid many variables to store intermediate results while ensuring the security gives birth to the STL \u0026lt;ranges\u0026gt;, which is likely to be used more widely than its Boost.ranges ancestor. The ranges library defines a lot of components for dealing with ranges, commonly-used view adapters included. With its various new features and improvements, it is called \u0026ldquo;the STL 2.0\u0026rdquo;.\nUse Ranges  Enable \u0026lt;ranges\u0026gt; is relatively easy, as a language feature of C++ 20, The only configuration needed is to set the language version to C++ 20 .\nMSVC 16.8 and Later In MSVC, set the language standard to \u0026ldquo;Features from the Latest C++ Working Draft\u0026rdquo; (/std:c++latest) in project\u0026rsquo;s Properties-\u0026gt;Configuration Properties-\u0026gt;General :\n Setting \nGCC-10 and Later In GCC, simply pass -std=c++20 to the compiler.\nImplementation Status It is worth mentioning that MSVC\u0026rsquo;s implementation is quite a partial one with inferior support for range adapters, and the Intellisense does not work well from time to time. However, there are some components of coroutines that only available in MSVC, so some of the code snippets below are compiled with and only with MSVC, and others are, and maybe only are compiled with GCC-11. For details, refer to Compiler support for C++20, or the C++ status page of certain compiler.\nRanges and Constrained Algorithms  Remeber how we use, for example, std::sort to sort a vector\u0026lt;int\u0026gt;? We always use iterators in the paradigm of [first,one_beyond_last) to express the elements that needs sorting, but given that we sort the whole container, is there any chance for it to be simplified? YES! with Ranges. As containers like a vector has the begin() and end() member, the container itself is a range, so with ranges following code can be write:\nvector\u0026lt;int\u0026gt; vec{3,5,2,8,10}; std::ranges::sort(vec);\tfor(auto i:vec) { cout\u0026lt;\u0026lt; i\u0026lt;\u0026lt;\u0026#34; \u0026#34;; } Such simpified STL algrithms are called Constrained algorithms. Nearly all STL algorithms have constrained version, which not only simplified the use, but also strengthen the ability of the ranges library if used with what\u0026rsquo;s discussed below.\nRanges and Range Adapters  Let\u0026rsquo;s begin with a relatively easy example. Now given a container of integers, the task is to get the first two even ones and get their squares. With ranges library, it\u0026rsquo;s straight forward to express the task as follows:\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;ranges\u0026gt; using namespace std; using namespace std::views; int main() { vector\u0026lt;int\u0026gt; vec{ 20,1,12,4,20,3,10,1 }; auto even = [](const int\u0026amp; a) { return a % 2 == 0; }; auto square = [](const int\u0026amp; a) {return a * a; }; for (int i : std::views::take(std::views::transform(std::views::filter(vec, even), square), 2)) { std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } return 0; } But, hey, is there any difference with traditional way to deal with containers? The prolonged and complicated nested function calling std::views::take(std::views::transform(std::views::filter(vec, even), square), 2) is the very thing that many programmers dislike to see, let along the complexity to add a new operation or change the order. Why isn\u0026rsquo;t it good to see? partly because readers should find the operands from the inner-most call and then read the parameters and recursively going out layer by layer. Constantly glancing forth and back is tiring, right? So it\u0026rsquo;s time to introduce what really pleased me of the ranges library: the pipeline operator.\nAs a noticeable feature of ranges library, the pipeline operator | means delivering the output of its left-hand operand as the input to its right-hand operand. This enables a elegant way to express a sequence of operations for something, or somehow a functional-style programming. With the magic of it, we can turn the traditional composing syntax to the following code :\nfor (int i : vec | filter(even) | transform([](const int\u0026amp; a) {return a * a; }) | take(2)) { cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } Pretty and clear, isn\u0026rsquo;t it ? the container and the operations on it are concatenated with the pipeline operator and is used by the range-based for. When reading the code, we glance the operands of the pipeline operators line by line, providing a very nature and easy way to understand the code. It is the relief of mental burden that reduces the change of producing buggy code.\nfilter() , transform(), and take() plays an important part in the code above, which are called range adapters. Range adapters take viewable_ranges as their parameters and can be called by the pipe operators. The standard library defined a set of range adapters (Ranges on cppreference), which provide various transformation on ranges. For example, to join many containers, the code below can be simply write:\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; vec2{ {1,2},{3,4},{5,6} }; for (auto i : vec2 | std::views::join)cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34; \u0026#34;; which gives the output:\n 1 2 3 4 5 6\n Also by using std::views::join, we can concatenate strings:\nauto parts={\u0026#34;c\u0026#34;sv,\u0026#34;+\u0026#34;sv,\u0026#34;+\u0026#34;sv,\u0026#34;20\u0026#34;sv}; for (auto c : parts | std::views::join)cout \u0026lt;\u0026lt; c; which gives the output:\n c++20\n Moreover, we can take element from a container of tuples by using std::views::elements :\nvector\u0026lt;tuple\u0026lt;int, int, int\u0026gt;\u0026gt; vec3{{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}; for (auto e : vec3 | std::views::elements\u0026lt;1\u0026gt;) cout \u0026lt;\u0026lt; e \u0026lt;\u0026lt; endl; The outputs are\n 2\n5\n8\n With these range adapters' help, it is no longer a problem to write elegant code to operate ranges with good readability. But what concerns to C++ programmers is that, what about performance ?\nLazy Evaluation  C++ programmers cares about performance, so how does the \u0026lt;ranges\u0026gt; library ensure it? the key is lazy evaluation. Lets take the a simple code snippet as a example.\nvector\u0026lt;int\u0026gt; vec{ 20,1,12,4,20,3,10,1 }; auto v = vec | filter(even) | transform([](const int\u0026amp; a) {return a * a; })| take(2) cout \u0026lt;\u0026lt; *v.begin() \u0026lt;\u0026lt; endl; Here the whole expression of the second line auto v = ... generates a view, neither modifying what in vec, nor copying any elements to elsewhere and storing theme. In other words, the construct of v has nothing to do with the size of vec.\nThen we print *v.begin(), which is when the evaluation happens. The on-demand evaluation not only ensure that they can be used everywhere iterators can be used, but also make sure the performance with complicated transformations, for evaluation happens just when the value is used and will not happen a second time. Sounds great, isn\u0026rsquo;t it? If only it can play with not only STL containers.\nRanges and Coroutines  Coroutine is indeed the focus of C++ 20, which enjoys great popularity even before its release. Coroutines are, in simple words, functions that can suspend and resume. Isn\u0026rsquo;t it traits give you a strong sense that it\u0026rsquo;s a good couple with the ranges library, given that it has the lazy evaluation feature?\nFor example, with Coroutines (C++20), it\u0026rsquo;s easy to write a Fibonacci generator like this:\n// #include \u0026lt;experimental/generator\u0026gt; on MSVC 16.8 experimental::generator\u0026lt;uint64_t\u0026gt; fib(uint32_t n) noexcept { uint64_t buf[3] = { 1,1 }; for (uint32_t i = 0; i \u0026lt; n; i++) { if (i \u0026gt;= 2) { buf[i % 3] = buf[(i - 1) % 3] + buf[(i - 2) % 3]; } co_yield buf[i % 3]; } co_return; } It is surely not what we regard as a container, which all the examples above dealt with. However, remember what mentioned in the beginning that :\n A range is a concept.\n Given that a generator has begin() and end() member, it satisfies the concept and therefore cooperates well with the ranges library. The code below demonstrates how to filter even numbers from the first 15 elements of the Fibonacci sequence.\nauto fib_gen = fib(15); auto even_fib=fib_gen | views::filter([](const int\u0026amp; a) {return a%2==0;}); And, with the help of coroutines and ranges, till now, no real evaluation happens, until we really use some of its values, like iterating through the even numbers:\nfor (auto\u0026amp; v : even_fib) { cout \u0026lt;\u0026lt; v \u0026lt;\u0026lt; endl; } which gives the output:\n Even fibonacci numbers \nEpilogue  Ranges, as a important and useful library component, deserve the \u0026ldquo;STL 2.0\u0026rdquo; name, and provides a uniform way to express the concept of range and compose transformation and STL algorithms. Although the ranges are not aimed to replace iterators, they reduce the explicit use of iterators, simplifying code.\nWith ranges and coroutines, more effective programs with elegant code and good code readability will be really easy to achieve, which handle IO delays and parallelism well. In the near future, Networking TS is going to be merged into C++23, when coroutines and ranges can be used widely by larger number of applications. For example, const_buffer and mutable_buffer of the Networking TS satisfy the range concept.\nFurther Reading  1. Thriving in a Crowded and Changing World: C++ 2006–2020, Bjarne Stroustrup. This paper demonstrate the history of modern C++ (C++11 and later) and gives a comprehensive view of language and library features like concepts, coroutines and ranges, as well as their history.\n2.Ranges TS and (Coroutines TS) Standard documents about the ranges library and coroutines.\n3.A beginner\u0026rsquo;s guide to C++ Ranges and Views. Very concrete introduction to the ranges concepts and views.\n","date":"2021-02-07T23:40:03+08:00","permalink":"https://xkzzzzzz.xyz/posts/cpp20-ranges-at-first-glance/","title":"C++20 Ranges at First Glance"},{"content":"Now, at the beginning of 2021, while celebrating the anniversary of this project, where most of my effort in the past year was devoted, it\u0026rsquo;s vital to make clear the road head for it.\nHindsight What has been done for it in the past year and a few months? Above growing from the very first assembly file to a large project with tens of thousands of lines of code, these aspects stands out:\n  The Improvement of infrastructures of kernel at the end of 2020, after 4 months struggling with file system, a minimum subset of EXT2 which support common operations like reading, creating and writing are implemented with a complete VFS abstraction. For the first time RAII and class hierarchy were adopted for kernel components. With the filesystem, all the modules of a usable kernel have been worked on more or less.\n  Reliable build system has been adopted Growing larger and larger, it\u0026rsquo;s difficult to manage the project by traditional makefiles, which is why CMake was introduced at earlier time last year. And after the long time working on the project, the decision turns out to be right. CMake provides a powerful tool to manage the project, as well as external dependencies.\n  Code style and best practices were formed Working long time with kernel, code styles like naming conventions have gained stability, and common best practices on kernel coding have been figured out.\n  Now   Better process model\n  Optimized memory management\n  Cache for file system\n  Refactoring and resource leaks fixing\n  Future   Move things out of kernel\n  Improved synchronization infrastructures\n  Rights and security\n  ","date":"2021-01-30T23:55:00+08:00","exists":true,"isDefault":false,"permalink":"/posts/project-dionysus-vision-of-2021/dionysus.jpg","resource":{},"title":"Project Dionysus : The Vision of 2021"},{"content":"Prologue  Dating back to a year ago, when I was attempting to add various features to the original rexv6-2 project, I am trapped by some very tough issues. I had been ambitious about the plan, but many of them turn out to be too hard to be carried out, and some of the original code of xv6, frankly speaking, is somehow out of date. That\u0026rsquo;s when it flashed on me that it may be better to build a new one from scratch. At that time, I meet the series of papers about minix3 and the concept of microkernel, and exokernel, described by a paper from MIT. They were really appealed to me. In the following months, it gradually become the main work for me, and soon turned to be the longest-lasting personal project of mine.\nWhy Operation System Kernel?  As science and technologies advancing, all the devices are becoming powerful, bringing the concept of \u0026ldquo;Install and remove apps\u0026rdquo; everywhere, following the increasingly urgent need of reliable operation system kernels equipped with modern concepts and consensus. Among all the needs, security and reliability should be the top. Intricate problem involved, it is impossible to keep the old routines. The new kernels recently appear in the industry, Google\u0026rsquo;s zircon for example, regard the concepts of microkernel, strictly isolated processes, and the well-encapsulated resource management as the key to success in the future. As the new consensus of the industry, these concepts must be invaluable for me, a freshman planning to major computer science, to acquire proficiency in. That\u0026rsquo;s the ultimate aim of project Dionysus.\nWhat\u0026rsquo;s the Principles of Development   Care about kernel itself first.\nHaving learned from previous attempts and failures, In this project, grub2 is used to boot the kernel, to block away the details and tricks that are too legacy. And user applications, shells, and GUI are not priorities.\n  Application of data structures and algorithms\nBeing more familiar with data structures and algorithms with deeper understanding, It\u0026rsquo;s high time I should use it in a project and observe their pros and cons in production.\n  Understand every details, and choose the best\nI regard this as a serious project to learn. So I shall figure out all every detail including how popular operation system do and why they do like that and choose the best means among them so as to deepen my understanding about operation system.\n  What\u0026rsquo;s Going on Now?  Despite the ultimate aim, the more advanced a concept is, the harder it is for an individual to implement. So now the job is to first build a usable kernel on the mature techniques and concepts that popular operation system kernels mostly rely on. By now, the following modules had been covered partly or completely:\n Memory management Drivers Process management Power management File system Facilities for user apps Framework and libraries that all the above involved   And they are now temporarily built into a macro kernel but are neatly divided and isolated from each other, making it possible for future changes.\n Dionysus kernel, after finishing booting and initializations \nBecause of the complexity of file system and the design of interfaces, the development has been slow recently . A rough schedule is to finishe file system by the end of 2020, and finished other kernel modules by mid-2021.\nWhat\u0026rsquo;s the Plan for the Future?  Dionysus kernel, future architecture simple diagram \nTo achieve the goal, after all the features are tested to work well, the first step is to implement a object manager to provide uniform interface and security guard for all the resource, making all the resources appears to be handles. and then the modules will be moved to separate processes running under kernel privileges.\nThe reason why system servers still run under kernel privileges is to simplify the development work. And two separate sets of API provided will make it easy to port existent Linux apps like LLVM C/C++ standard libraries and compiler kits.\nAs another goal for me, a hand-made simple compiler may be implemented and used in the accomplished project, but so far there\u0026rsquo;s no plan to build a kernel with custom compilers.\nEpilogue  I remember that I have had the idea to implement a kernel very early after I learn how to code. The urge become so strong that I make the first attempt when I graduate from junior high school, when I even find it difficult to understand the difference between physical memory and virtual memory. Then I made a few attempts afterwards, slowly becoming aware of the key points of kernel and how to build a kernel. During times of try and fail, I gradually know how to work with Linux distributions and start to fall under the spell of the philosophy of UNIX. And then I learned more, and finally became determined to write my own. I am serious, and I will try my best this time to build a usable one with everything I\u0026rsquo;d ever imagined on it.\n","date":"2020-10-11T16:25:35+08:00","exists":true,"isDefault":false,"permalink":"/posts/project-dionysus-why-and-what/bootup.png","resource":{},"title":"Project Dionysus - Why and What"},{"content":"Introduction Being considered as the three romances of a programmer, An OS is both challenging and interesting project to dive in. As a mature codebase of operation system study, xv6 is a good re-implementation of Unix v6, which is used by MIT\u0026rsquo;s 6.828. This project aims at apply improvements on the a quasi-original codebase of xv6 (xv6-improved) , adding including new kernel features and user support so as to create a linux-like full-featured kernel, including some modern techniques, such as MLFQ scheduling and an extended file system.\nTaking the mistakes of the 1st generation rexv6 project into consideration, the project will firstly be improved on the vital parts such as processes and memory management. Then filesystem and shell will be tweaked and a graphic framework will be finally constructed.\nIn the implement of all the features, the algorithms and data structure will be thought over discreetly and put in the first place, instead of the feature itself or the amount of the features, so as to gain great efficiency.\nGoals Uncomplete and unsorted goals are listed below:\n Lottery Scheduler FAT32 support Signals File structures and make system manipulations Support for various file systems and driver types Separating device driver from the kernel Memory management tweaks Shell and GUI POSIX compatibility  Try it out  Starup Screen \nWhat you need   A available Linux environment with Qemu installed.\nThe alternatives includes WSL and any other virtual PCs. I am using Debian on WSL.\n  Build-essentials, or at least GNU tools such as gdb and gcc.\nGCC 6.3.0 is being used.\n  Clone The project is hosted at rexv6-2\n$ git clone https://github.com/SmartPolarBear/rexv6-2.git\nBuild $ make qemu\n","date":"2019-05-30T23:11:01+08:00","exists":true,"isDefault":false,"permalink":"/posts/announcing-rexv6-proj/startup.png","resource":{},"title":"Announcing the Re-xv6-2 project"},{"content":"Hands-On This morning I finally received my Raspberry Pi, after an eight-day-long delivery. Raspberry Pi 3B+, released in 2018, as is said, is more powerful than its predecessor. The first step after opening the box is to add two head sinks on the chip. The CPU doesn\u0026rsquo;t need one although its performance has been greatly improved, for it already has one. The given box has no reserved space for GPIO pins, which make it impossible to use it with GPIO peripherals. Therefore, my trick is that I installed a half of the box opposite down like what\u0026rsquo;s shown below.\n Raspberry 3B+ \nSetup I planed to run Windows 10 IoT at first, but finally I decided to use Raspbian as the support for 3B+ has not been officially released. The preview version is buggy and what\u0026rsquo;s worse, it can\u0026rsquo;t support the on-board Wi-Fi.\nAs for setup, convenient as it is generally, there\u0026rsquo;s a big obstacle that I don\u0026rsquo;t have either a network cable or a set of keyboard and mouse. Moreover, my main PC runs Windows, which make the process more complicated.\nFor a headless setup, we need two computers if your main computer runs Windows. As we often do for Pi on Windows, I format the micro SD card and write the Raspbian image with SD Card Formatter from Tuxera Inc. and Rufus. Then, the step is a bit different than common. After mounting the card on a Linux computer, edit the file located in /etc/wpa_supplicant/wpa_supplicant.conf . For example, we use nano.\nsudo nano /etc/wpa_supplicant/wpa_supplicant.conf And append a network section like below:\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=\u0026#34;Your wifi\u0026#39;s SSID\u0026#34; psk=\u0026#34;Password\u0026#34; key_mgmt=WPA-PSK } If you are living in China, don\u0026rsquo;t forget a country=CN before the network section. Then insert the card, whose slot should be in the other end of USBs on the board, and power on the Pi. When the red light is on and the green light is off, you can notice a new device in your router\u0026rsquo;s management page, which is often 192.168.1.1 or 192.168.3.1. My Pi shows as a dhcpcd-6.11.5-armv7l in the router\u0026rsquo;s management page with the IP shown in the screenshot.\n Raspberry 3B+’s IP \nWith the IP address shown, we can easily connect to the Pi by any ssh tools. For example, putty.\n Putty \nLogin and Have Fun As a Raspberry Pi denies a remote connection to the root user, we should login with pi user and the default password is raspberry. The connection should be established well now and you can do anything with this tiny Linux device. Have fun!\nWhat\u0026rsquo;s Next In the next passage I am going to control a LED matrix with GPIO pins. I will write a program in C++ or Python3 to control the MAX7219 module.\nReference  How to set up Raspberry Pi without a monitor? 树莓派 Raspberry Pi 3 无显示器安装 Troubleshooting, Raspberry Pi 3B+ booting issues   ","date":"2019-02-23T19:40:08+08:00","exists":true,"isDefault":false,"permalink":"/posts/resp-pi-headless-setup/Pi1.png","resource":{},"title":"Respberry Pi 3B+ Headless Setup"}]